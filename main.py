from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import json
import re
from openai import OpenAI
import os
from dotenv import load_dotenv
import instructor
from pydantic import BaseModel, Field

load_dotenv()

app = FastAPI()

# âœ¨ ×××¤×©×¨ ×’×™×©×” ××”-Frontend ×©×‘-Render
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ××¤×©×¨ ×’× ×œ×©×™× ×¤×” ×“×•××™×™×Ÿ ×¡×¤×¦×™×¤×™
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

client = instructor.from_openai(OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
))
MODEL = "gpt-4o-mini"

# ×˜×•×¢×Ÿ ××ª ×”× ×ª×•× ×™× ××§×•×‘×¥ Excel
df = pd.read_excel("data.xlsx")

# ××‘× ×” ×”×‘×§×©×” ××”××•×“×œ
class TripDetails(BaseModel):
    related: bool = Field(description="×”×× ×”×©××œ×” ×¨×œ×•×•× ×˜×™×ª ×œ×˜×™×•×œ×™×?")
    region: str = Field(description="×”××–×•×¨ ×‘××¨×¥. ××—×“ ×: ×¦×¤×•×Ÿ,×“×¨×•×,××¨×›×–")
    difficulty: str = Field(description="×§×•×©×™. ××—×“ ×: ×§×œ,×‘×™× ×•× ×™,×§×©×”")
    has_water: bool

@app.post("/ask")
async def ask_route(request: Request):
    data = await request.json()
    user_question = data.get("message", "")

    # ×©×œ×‘ ×¨××©×•×Ÿ: ×—×™×œ×•×¥ ×¤×¨×˜×™ ×”×˜×™×•×œ ××ª×•×š ×”×©××œ×”
    trip_details = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "system", "content": "××ª×” ××“×¨×™×š ×˜×™×•×œ×™× ××•××—×” ×‘×™×©×¨××œ"},
            {"role": "user", "content": user_question}
        ],
        response_model=TripDetails
    )

    if not trip_details.related:
        return {"response": "×× ×™ ×¢×•×–×¨ ×¨×§ ×‘×˜×™×•×œ×™× ğŸ™‚"}

    # ×¡×™× ×•×Ÿ ×œ×¤×™ ×”×§×¨×™×˜×¨×™×•× ×™×
    filtered = df.copy()
    filtered = filtered[filtered["region"] == trip_details.region]
    filtered = filtered[filtered["has_water"] == trip_details.has_water]
    filtered = filtered[filtered["difficulty"] == trip_details.difficulty]

    if filtered.empty:
        return {"response": "×œ× ××¦××ª×™ ××¡×œ×•×œ ××ª××™× ×œ×¤×™ ×”×‘×§×©×”. ××•×œ×™ ×ª× ×¡×” ×œ×©× ×•×ª ××©×”×•?"}

    suggestions = "\n".join([
        f"{row['name']} â€“ {row['×ª×™××•×¨ ×§×¦×¨']} ({row['region']}, {row['difficulty']})"
        for _, row in filtered.head(3).iterrows()
    ])

    final_prompt = (
        f"×”××©×ª××© ××—×¤×© ××¡×œ×•×œ. ×”× ×” ×›××” ×”×¦×¢×•×ª:\n{suggestions}\n"
        "×‘×—×¨ ××ª ×”××•××œ×¥ ×‘×™×•×ª×¨ ×•×”×¡×‘×¨ ×œ××”."
    )

    final_response = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "system", "content": "××ª×” ××“×¨×™×š ×˜×™×•×œ×™× ××•××—×” ×‘×™×©×¨××œ."},
            {"role": "user", "content": final_prompt}
        ],
        response_model=str
    )

    return {"response": str(final_response)}