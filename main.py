from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import json
import os
from dotenv import load_dotenv
from pydantic import BaseModel, Field
from openai import OpenAI
from difflib import SequenceMatcher, get_close_matches
import instructor
from sklearn.cluster import KMeans
from sklearn.preprocessing import LabelEncoder

load_dotenv()

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

client = instructor.from_openai(OpenAI(api_key=os.getenv("OPENAI_API_KEY")))
MODEL = "gpt-4o-mini"

# ×˜×¢×Ÿ ××ª ×”×§×•×‘×¥
try:
    df = pd.read_excel("data.xlsx")
except Exception as e:
    df = pd.DataFrame()
    print(f"âš ï¸ ×œ× × ×˜×¢×Ÿ ×§×•×‘×¥ ×”× ×ª×•× ×™×: {e}")

# Clustering ×¢×œ ×”××¡×œ×•×œ×™×
try:
    df_clustering = df.copy()
    label_cols = ["region", "difficulty", "× ×’×™×©×•×ª"]
    for col in label_cols:
        df_clustering[col] = LabelEncoder().fit_transform(df_clustering[col].astype(str))

    df_clustering["has_water"] = df_clustering["has_water"].astype(int)
    df_clustering["××•×¨×š ××¡×œ×•×œ (×§\"×)"] = pd.to_numeric(df_clustering["××•×¨×š ××¡×œ×•×œ (×§\"×)"], errors="coerce").fillna(0)

    features = ["region", "difficulty", "× ×’×™×©×•×ª", "has_water", "××•×¨×š ××¡×œ×•×œ (×§\"×)"]
    X = df_clustering[features]
    kmeans = KMeans(n_clusters=4, random_state=42)
    df_clustering["cluster"] = kmeans.fit_predict(X)
except Exception as e:
    print(f"âš ï¸ ×©×’×™××” ×‘-Clustering: {e}")

class TripDetails(BaseModel):
    related: bool = Field(description="×”×× ×”×©××œ×” ×¨×œ×•×•× ×˜×™×ª ×œ×˜×™×•×œ×™×?")
    region: str = Field(description="×”××–×•×¨ ×‘××¨×¥. ××—×“ ×: ×¦×¤×•×Ÿ,×“×¨×•×,××¨×›×–")
    difficulty: str = Field(description="×§×•×©×™. ××—×“ ×: ×§×œ,×‘×™× ×•× ×™,×§×©×”")
    has_water: bool

class ExtraFilter(BaseModel):
    wants_accessibility: bool = Field(description="×”×× ×”××©×ª××© ×¨×•×¦×” ×©×”××¡×œ×•×œ ×™×”×™×” × ×’×™×©?")
    max_length_km: float = Field(description="××•×¨×š ××§×¡×™××œ×™ ×©×œ ×”××¡×œ×•×œ ×‘×§×™×œ×•××˜×¨×™×", default=0.0)

def levenshtein_distance(s1, s2):
    if len(s1) < len(s2):
        return levenshtein_distance(s2, s1)
    if len(s2) == 0:
        return len(s1)
    previous_row = range(len(s2) + 1)
    for i, c1 in enumerate(s1):
        current_row = [i + 1]
        for j, c2 in enumerate(s2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row
    return previous_row[-1]

def is_similar_to_greeting(text):
    greetings = ["×©×œ×•×", "×”×™×™", "×”×™", "××”×œ×Ÿ", "××” × ×©××¢", "××” ×©×œ×•××š", "××” ×§×•×¨×”", "×‘×•×§×¨ ×˜×•×‘", "×¢×¨×‘ ×˜×•×‘"]
    text = text.replace("?", "").replace(",", "").replace("!", "").strip().lower()
    return any(levenshtein_distance(text, greet) <= 1 for greet in greetings)

@app.post("/ask")
async def ask_route(request: Request):
    data = await request.json()
    user_question = data.get("message", "").strip()
    context = data.get("context", {})

    if is_similar_to_greeting(user_question):
        return {"response": "×©×œ×•×! ×× ×™ ×›××Ÿ ×›×“×™ ×œ×¢×–×•×¨ ×œ×š ×œ××¦×•× ××¡×œ×•×œ×™ ×˜×™×•×œ ×‘×™×©×¨××œ ğŸï¸ ×©××œ ××•×ª×™ ×¢×œ ××–×•×¨, ×§×•×©×™, ××™× ××• ×›×œ ×“×‘×¨ ×©×§×©×•×¨ ×œ×˜×™×•×œ×™×."}

    if context.get("followup_required"):
        followup_answer = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "××©×ª××© × ×©××œ ×”×× ×—×©×•×‘×” ×œ×• × ×’×™×©×•×ª ×œ× ×›×™× ×•××•×¨×š ××§×¡×™××œ×™ ×©×œ ×”××¡×œ×•×œ. "
                        "×”×—×–×¨ JSON ×¢× ×©× ×™ ×©×“×•×ª: wants_accessibility (true/false), max_length_km (××¡×¤×¨). "
                        "×× ×œ× ×—×©×•×‘ ×œ×• â€“ ×”×—×–×¨ false ×•Ö¾0 ×‘×”×ª×××”."
                    )
                },
                {"role": "user", "content": user_question}
            ],
            response_model=ExtraFilter
        )

        trip_details = TripDetails(
            related=True,
            region=context.get("region"),
            difficulty=context.get("difficulty"),
            has_water=context.get("has_water")
        )
        extra_filters = followup_answer

        filtered = df.copy()
        if trip_details.region:
            filtered = filtered[filtered["region"] == trip_details.region]
        if isinstance(trip_details.has_water, bool):
            filtered = filtered[filtered["has_water"] == trip_details.has_water]
        if trip_details.difficulty:
            filtered = filtered[filtered["difficulty"] == trip_details.difficulty]
        if extra_filters.wants_accessibility:
            filtered = filtered[filtered["× ×’×™×©×•×ª"].astype(str).str.contains("× ×’×™×©", na=False)]
        if extra_filters.max_length_km > 0:
            filtered = filtered[pd.to_numeric(filtered["××•×¨×š ××¡×œ×•×œ (×§\"×)"], errors="coerce") <= extra_filters.max_length_km]

        if filtered.empty:
            return {"response": "×œ× ××¦××ª×™ ××¡×œ×•×œ ××ª××™× ×œ×¤×™ ×”×‘×§×©×”. ××•×œ×™ ×ª× ×¡×” ×œ×©× ×•×ª ××©×”×•?"}

        suggestions = "\n".join([
            f"{row['name']} â€“ {row['×ª×™××•×¨ ×§×¦×¨']} ({row['region']}, {row['difficulty']})"
            for _, row in filtered.head(3).iterrows()
        ])

        final_prompt = (
            f"×”××©×ª××© ××—×¤×© ××¡×œ×•×œ. ×”× ×” ×›××” ×”×¦×¢×•×ª:\n{suggestions}\n"
            "×‘×—×¨ ××ª ×”××•××œ×¥ ×‘×™×•×ª×¨ ×•×”×¡×‘×¨ ×œ××”."
        )

        final_response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "××ª×” ××“×¨×™×š ×˜×™×•×œ×™× ××•××—×” ×‘×™×©×¨××œ."},
                {"role": "user", "content": final_prompt}
            ],
            response_model=str
        )

        return {"response": str(final_response)}

    else:
        trip_details = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "××ª×” ××“×¨×™×š ×˜×™×•×œ×™× ××•××—×” ×‘×™×©×¨××œ. "
                        "×”××˜×¨×” ×”×™× ×œ×—×œ×¥ ××”×©××œ×” ×©×œ ×”××©×ª××© ×©×œ×•×©×” ×¤×¨××˜×¨×™×: "
                        "××–×•×¨ ×‘××¨×¥ (region), ×¨××ª ×§×•×©×™ (difficulty), ×•×”×× ×™×© ××™× ×‘××¡×œ×•×œ (has_water). "
                        "×× ×œ× × ×××¨ ××¡×¤×™×§ ××™×“×¢, ××‘×œ ××“×•×‘×¨ ×‘×ª×—×•× ×”×˜×™×•×œ×™× â€“ ×§×‘×¢ related=True, ××‘×œ ×”×©××¨ ××ª ×”×¢×¨×›×™× ×¨×™×§×™×. "
                        "×× ×–×• ×œ× ×©××œ×” ×©×§×©×•×¨×” ×‘×›×œ×œ ×œ×˜×™×•×œ×™× â€“ ×§×‘×¢ related=False ×‘×œ×‘×“."
                    )
                },
                {"role": "user", "content": user_question}
            ],
            response_model=TripDetails
        )

        if not trip_details.related:
            return {"response": "×× ×™ ×›××Ÿ ×›×“×™ ×œ×¢×–×•×¨ ×¨×§ ×‘×˜×™×•×œ×™× ğŸ™‚ × ×¡×” ×œ×©××•×œ ×¢×œ ××¡×œ×•×œ, ××–×•×¨ ×‘××¨×¥, ××™× ××• ×¨××ª ×§×•×©×™."}

        filled_fields = sum([
            bool(trip_details.region),
            bool(trip_details.difficulty),
            isinstance(trip_details.has_water, bool)
        ])

        if filled_fields < 2:
            return {"response": "×›×“×™ ×©××•×›×œ ×œ×”××œ×™×¥ ×œ×š ×¢×œ ××¡×œ×•×œ ××ª××™×, × ×¡×” ×œ×¦×™×™×Ÿ ×œ×¤×—×•×ª ×©× ×™ ×¤×¨×˜×™× â€“ ××–×•×¨, ×¨××ª ×§×•×©×™ ××• ×× ×™×© ××™× ğŸŒŠ"}

        return {
            "response": "×¨×§ ×©××œ×” ××—×¨×•× ×” ğŸ™‚ ×”×× ×—×©×•×‘ ×œ×š ×©×”××¡×œ×•×œ ×™×”×™×” × ×’×™×© ×œ× ×›×™×? ×•××” ×”××•×¨×š ×”××§×¡×™××œ×™ ×©×ª×¨×¦×”?",
            "context": {
                "followup_required": True,
                "user_question": user_question,
                "region": trip_details.region,
                "difficulty": trip_details.difficulty,
                "has_water": trip_details.has_water
            }
        }

@app.post("/similar")
async def get_similar_routes(request: Request):
    data = await request.json()
    route_name = data.get("route_name")

    all_names = df_clustering["name"].astype(str).tolist()
    match = get_close_matches(route_name, all_names, n=1, cutoff=0.6)

    if not match:
        return {"response": "×œ× ××¦××ª×™ ××ª ×”××¡×œ×•×œ ×”×–×” ğŸ˜•"}

    closest = match[0]
    cluster_id = df_clustering[df_clustering["name"] == closest]["cluster"].values[0]
    similar_routes = df_clustering[df_clustering["cluster"] == cluster_id]
    similar_routes = similar_routes[similar_routes["name"] != closest].head(5)

    if similar_routes.empty:
        return {"response": f"×œ× ××¦××ª×™ ××¡×œ×•×œ×™× ×“×•××™× ×œÖ¾{closest} ğŸ˜•"}

    suggestions = "\n".join([
        f"{row['name']} â€“ {row['×ª×™××•×¨ ×§×¦×¨']} ({row['region']}, {row['difficulty']})"
        for _, row in similar_routes.iterrows()
    ])

    return {"response": f"×”× ×” ××¡×œ×•×œ×™× ×“×•××™× ×œÖ¾{closest}:\n{suggestions}"}
