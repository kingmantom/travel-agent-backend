from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import json
import re
from openai import OpenAI
import os
from dotenv import load_dotenv
load_dotenv()
import instructor
from pydantic import BaseModel, Field

app = FastAPI()

# âœ¨ ×××¤×©×¨ ×’×™×©×” ××”-Frontend ×©×‘-Render
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

client = instructor.from_openai(OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
))
MODEL = "gpt-4o-mini"

# ×˜×•×¢×Ÿ ××ª ×”× ×ª×•× ×™× ××§×•×‘×¥ Excel
df = pd.read_excel("data.xlsx")

# ××‘× ×” ×”×‘×§×©×” ××”××•×“×œ
class TripDetails(BaseModel):
    related: bool = Field(description="×”×× ×”×©××œ×” ×¨×œ×•×•× ×˜×™×ª ×œ×˜×™×•×œ×™×?")
    region: str = Field(description="×”××–×•×¨ ×‘××¨×¥. ××—×“ ×: ×¦×¤×•×Ÿ,×“×¨×•×,××¨×›×–")
    difficulty: str = Field(description="×§×•×©×™. ××—×“ ×: ×§×œ,×‘×™× ×•× ×™,×§×©×”")
    has_water: bool

@app.post("/ask")
async def ask_route(request: Request):
    data = await request.json()
    user_question = data.get("message", "").strip()

    # ğŸŸ¢ ×ª×•×¡×¤×ª â€“ ×‘×“×™×§×ª ×‘×¨×›×” ×‘×œ×‘×“
    greetings = ["×©×œ×•×", "×”×™×™", "×”×™", "××”×œ×Ÿ", "××” × ×©××¢", "××” ×©×œ×•××š", "××” ×§×•×¨×”", "×‘×•×§×¨ ×˜×•×‘", "×¢×¨×‘ ×˜×•×‘"]
    if user_question.lower() in [g.lower() for g in greetings]:
        return {
            "response": "×©×œ×•×! ×× ×™ ×›××Ÿ ×›×“×™ ×œ×¢×–×•×¨ ×œ×š ×œ××¦×•× ××¡×œ×•×œ×™ ×˜×™×•×œ ×‘×™×©×¨××œ ğŸï¸ ×©××œ ××•×ª×™ ×¢×œ ××–×•×¨, ×§×•×©×™, ××™× ××• ×›×œ ×“×‘×¨ ×©×§×©×•×¨ ×œ×˜×™×•×œ×™×."
        }

    # ×—×™×œ×•×¥ ×¤×¨×˜×™ ×”×˜×™×•×œ ××ª×•×š ×”×©××œ×”
    trip_details = client.chat.completions.create(
        model=MODEL,
        messages=[
            {
                "role": "system",
                "content": (
                    "××ª×” ××“×¨×™×š ×˜×™×•×œ×™× ××•××—×” ×‘×™×©×¨××œ. "
                    "×”××˜×¨×” ×”×™× ×œ×—×œ×¥ ××”×©××œ×” ×©×œ ×”××©×ª××© ×©×œ×•×©×” ×¤×¨××˜×¨×™×: "
                    "××–×•×¨ ×‘××¨×¥ (region), ×¨××ª ×§×•×©×™ (difficulty), ×•×”×× ×™×© ××™× ×‘××¡×œ×•×œ (has_water). "
                    "×× ×œ× × ×××¨ ××¡×¤×™×§ ××™×“×¢, ××‘×œ ××“×•×‘×¨ ×‘×ª×—×•× ×”×˜×™×•×œ×™× â€“ ×§×‘×¢ related=True, ××‘×œ ×”×©××¨ ××ª ×”×¢×¨×›×™× ×¨×™×§×™×. "
                    "×× ×–×• ×œ× ×©××œ×” ×©×§×©×•×¨×” ×‘×›×œ×œ ×œ×˜×™×•×œ×™× â€“ ×§×‘×¢ related=False ×‘×œ×‘×“."
                )
            },
            {"role": "user", "content": user_question}
        ],
        response_model=TripDetails
    )

    # ×©××œ×” ×œ× ×§×©×•×¨×” ×‘×›×œ×œ ×œ×˜×™×•×œ×™×
    if not trip_details.related:
        return {"response": "×× ×™ ×›××Ÿ ×›×“×™ ×œ×¢×–×•×¨ ×¨×§ ×‘×˜×™×•×œ×™× ğŸ™‚ × ×¡×” ×œ×©××•×œ ×¢×œ ××¡×œ×•×œ, ××–×•×¨ ×‘××¨×¥, ××™× ××• ×¨××ª ×§×•×©×™."}

    # ×× ×¤×—×•×ª ×-2 ×¤×¨×˜×™× ××•×œ××•
    filled_fields = sum([
        bool(trip_details.region),
        bool(trip_details.difficulty),
        isinstance(trip_details.has_water, bool)
    ])

    if filled_fields < 2:
        return {"response": "×›×“×™ ×©××•×›×œ ×œ×”××œ×™×¥ ×œ×š ×¢×œ ××¡×œ×•×œ ××ª××™×, × ×¡×” ×œ×¦×™×™×Ÿ ×œ×¤×—×•×ª ×©× ×™ ×¤×¨×˜×™× â€“ ××–×•×¨, ×¨××ª ×§×•×©×™ ××• ×× ×™×© ××™× ğŸŒŠ"}

    # ×¡×™× ×•×Ÿ ×œ×¤×™ ×”×§×¨×™×˜×¨×™×•× ×™×
    filtered = df.copy()
    if trip_details.region:
        filtered = filtered[filtered["region"] == trip_details.region]
    if isinstance(trip_details.has_water, bool):
        filtered = filtered[filtered["has_water"] == trip_details.has_water]
    if trip_details.difficulty:
        filtered = filtered[filtered["difficulty"] == trip_details.difficulty]

    if filtered.empty:
        return {"response": "×œ× ××¦××ª×™ ××¡×œ×•×œ ××ª××™× ×œ×¤×™ ×”×‘×§×©×”. ××•×œ×™ ×ª× ×¡×” ×œ×©× ×•×ª ××©×”×•?"}

    suggestions = "\n".join([
        f"{row['name']} â€“ {row['×ª×™××•×¨ ×§×¦×¨']} ({row['region']}, {row['difficulty']})"
        for _, row in filtered.head(3).iterrows()
    ])

    final_prompt = (
        f"×”××©×ª××© ××—×¤×© ××¡×œ×•×œ. ×”× ×” ×›××” ×”×¦×¢×•×ª:\n{suggestions}\n"
        "×‘×—×¨ ××ª ×”××•××œ×¥ ×‘×™×•×ª×¨ ×•×”×¡×‘×¨ ×œ××”."
    )

    final_response = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "system", "content": "××ª×” ××“×¨×™×š ×˜×™×•×œ×™× ××•××—×” ×‘×™×©×¨××œ."},
            {"role": "user", "content": final_prompt}
        ],
        response_model=str
    )

    return {"response": str(final_response)}